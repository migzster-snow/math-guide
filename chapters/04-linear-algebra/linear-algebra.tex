\chapter{Linear Algebra}

Linear algebra studies vector spaces and linear transformations between them. This chapter covers the essential concepts and computational techniques.

\section{Matrices and Systems of Linear Equations}

\begin{definition}[Matrix]
An $m \times n$ \textbf{matrix} is a rectangular array of numbers arranged in $m$ rows and $n$ columns:
\[A = \begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{pmatrix}\]
\end{definition}

\begin{definition}[Matrix Addition]
If $A$ and $B$ are both $m \times n$ matrices, then $A + B$ is the $m \times n$ matrix whose $(i,j)$-entry is $a_{ij} + b_{ij}$.
\end{definition}

\begin{definition}[Matrix Multiplication]
If $A$ is an $m \times p$ matrix and $B$ is a $p \times n$ matrix, then $AB$ is the $m \times n$ matrix whose $(i,j)$-entry is:
\[(AB)_{ij} = \sum_{k=1}^{p} a_{ik}b_{kj}\]
\end{definition}

\begin{example}[Matrix Multiplication]
Let $A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}$ and $B = \begin{pmatrix} 5 & 6 \\ 7 & 8 \end{pmatrix}$. Then:
\[AB = \begin{pmatrix} 1 \cdot 5 + 2 \cdot 7 & 1 \cdot 6 + 2 \cdot 8 \\ 3 \cdot 5 + 4 \cdot 7 & 3 \cdot 6 + 4 \cdot 8 \end{pmatrix} = \begin{pmatrix} 19 & 22 \\ 43 & 50 \end{pmatrix}\]
\end{example}

\subsection{Gaussian Elimination}

\begin{definition}[Row Echelon Form]
A matrix is in \textbf{row echelon form} if:
\begin{enumerate}
    \item All nonzero rows are above any rows of all zeros
    \item Each leading entry is in a column to the right of the leading entry in the row above it
    \item All entries in a column below a leading entry are zeros
\end{enumerate}
\end{definition}

\begin{definition}[Reduced Row Echelon Form]
A matrix is in \textbf{reduced row echelon form} if it is in row echelon form and:
\begin{enumerate}
    \item The leading entry in each nonzero row is 1
    \item Each leading 1 is the only nonzero entry in its column
\end{enumerate}
\end{definition}

\section{Determinants}

\begin{definition}[Determinant (2×2)]
For a $2 \times 2$ matrix $A = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$:
\[\det(A) = ad - bc\]
\end{definition}

\begin{definition}[Determinant (n×n)]
For an $n \times n$ matrix $A$, the determinant can be computed using cofactor expansion:
\[\det(A) = \sum_{j=1}^{n} (-1)^{i+j} a_{ij} M_{ij}\]
where $M_{ij}$ is the $(i,j)$-minor of $A$.
\end{definition}

\begin{theorem}[Properties of Determinants]
Let $A$ and $B$ be $n \times n$ matrices. Then:
\begin{enumerate}
    \item $\det(AB) = \det(A)\det(B)$
    \item $\det(A^T) = \det(A)$
    \item If $A$ is invertible, then $\det(A^{-1}) = \frac{1}{\det(A)}$
    \item $\det(cA) = c^n \det(A)$ for scalar $c$
\end{enumerate}
\end{theorem}

\section{Vector Spaces and Subspaces}

\begin{definition}[Subspace]
A subset $W$ of a vector space $V$ is a \textbf{subspace} if:
\begin{enumerate}
    \item The zero vector is in $W$
    \item $W$ is closed under addition
    \item $W$ is closed under scalar multiplication
\end{enumerate}
\end{definition}

\begin{example}[Column Space]
The \textbf{column space} of an $m \times n$ matrix $A$ is the subspace of $\mathbb{R}^m$ spanned by the columns of $A$:
\[\text{Col}(A) = \{\mathbf{b} \in \mathbb{R}^m : A\mathbf{x} = \mathbf{b} \text{ has a solution}\}\]
\end{example}

\begin{definition}[Null Space]
The \textbf{null space} of an $m \times n$ matrix $A$ is:
\[\text{Null}(A) = \{\mathbf{x} \in \mathbb{R}^n : A\mathbf{x} = \mathbf{0}\}\]
\end{definition}

\section{Eigenvalues and Eigenvectors}

\begin{definition}[Eigenvalue and Eigenvector]
Let $A$ be an $n \times n$ matrix. A scalar $\lambda$ is an \textbf{eigenvalue} of $A$ if there exists a nonzero vector $\mathbf{v}$ such that:
\[A\mathbf{v} = \lambda\mathbf{v}\]
The vector $\mathbf{v}$ is called an \textbf{eigenvector} corresponding to $\lambda$.
\end{definition}

\begin{definition}[Characteristic Polynomial]
The \textbf{characteristic polynomial} of an $n \times n$ matrix $A$ is:
\[p(\lambda) = \det(A - \lambda I)\]
The eigenvalues of $A$ are the roots of this polynomial.
\end{definition}

\begin{example}[Finding Eigenvalues]
For $A = \begin{pmatrix} 3 & 1 \\ 0 & 2 \end{pmatrix}$:

\[A - \lambda I = \begin{pmatrix} 3-\lambda & 1 \\ 0 & 2-\lambda \end{pmatrix}\]

\[\det(A - \lambda I) = (3-\lambda)(2-\lambda) = \lambda^2 - 5\lambda + 6 = (\lambda-2)(\lambda-3)\]

So the eigenvalues are $\lambda_1 = 2$ and $\lambda_2 = 3$.
\end{example}

\begin{theorem}[Diagonalization]
An $n \times n$ matrix $A$ is diagonalizable if and only if $A$ has $n$ linearly independent eigenvectors. In this case, $A = PDP^{-1}$ where $D$ is diagonal and the columns of $P$ are eigenvectors of $A$.
\end{theorem}

\section{Inner Products and Orthogonality}

\begin{definition}[Inner Product]
An \textbf{inner product} on a real vector space $V$ is a function $\langle \cdot, \cdot \rangle : V \times V \to \mathbb{R}$ that satisfies:
\begin{enumerate}
    \item $\langle \mathbf{u}, \mathbf{v} \rangle = \langle \mathbf{v}, \mathbf{u} \rangle$
    \item $\langle \mathbf{u} + \mathbf{v}, \mathbf{w} \rangle = \langle \mathbf{u}, \mathbf{w} \rangle + \langle \mathbf{v}, \mathbf{w} \rangle$
    \item $\langle c\mathbf{u}, \mathbf{v} \rangle = c\langle \mathbf{u}, \mathbf{v} \rangle$
    \item $\langle \mathbf{v}, \mathbf{v} \rangle \geq 0$ with equality if and only if $\mathbf{v} = \mathbf{0}$
\end{enumerate}
\end{definition}

\begin{definition}[Orthogonal Vectors]
Two vectors $\mathbf{u}$ and $\mathbf{v}$ are \textbf{orthogonal} if $\langle \mathbf{u}, \mathbf{v} \rangle = 0$.
\end{definition}

\begin{definition}[Orthogonal Matrix]
A square matrix $Q$ is \textbf{orthogonal} if $Q^TQ = I$, or equivalently, $Q^{-1} = Q^T$.
\end{definition}

\begin{theorem}[Gram-Schmidt Process]
Given linearly independent vectors $\mathbf{v_1}, \mathbf{v_2}, \ldots, \mathbf{v_k}$, the Gram-Schmidt process produces orthogonal vectors $\mathbf{u_1}, \mathbf{u_2}, \ldots, \mathbf{u_k}$ such that $\text{span}\{\mathbf{u_1}, \ldots, \mathbf{u_j}\} = \text{span}\{\mathbf{v_1}, \ldots, \mathbf{v_j}\}$ for each $j$.
\end{theorem}

\section{Exercises}

\begin{enumerate}
    \item Compute $AB$ and $BA$ for $A = \begin{pmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{pmatrix}$ and $B = \begin{pmatrix} 1 & 4 \\ 2 & 5 \\ 3 & 6 \end{pmatrix}$.
    
    \item Find the determinant of $A = \begin{pmatrix} 2 & -1 & 3 \\ 1 & 0 & 4 \\ -2 & 1 & 1 \end{pmatrix}$.
    
    \item Determine if the vectors $\begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix}$, $\begin{pmatrix} 4 \\ 5 \\ 6 \end{pmatrix}$, and $\begin{pmatrix} 7 \\ 8 \\ 9 \end{pmatrix}$ are linearly independent.
    
    \item Find the eigenvalues and eigenvectors of $A = \begin{pmatrix} 4 & -2 \\ 1 & 1 \end{pmatrix}$.
    
    \item Use the Gram-Schmidt process to orthogonalize the vectors $\mathbf{v_1} = \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix}$ and $\mathbf{v_2} = \begin{pmatrix} 1 \\ 0 \\ 1 \end{pmatrix}$.
\end{enumerate}
