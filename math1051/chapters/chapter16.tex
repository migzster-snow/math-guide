\chapter{Eigenvalues and Eigenvectors}

Consider a linear transformation represented by a square matrix, denoted $A$. When a vector is transformed by the matrix, its direction and magnitude can change. Consider the unique case of special vectors, called \textbf{eigenvectors}, denoted $\underline{x}$, that only change in magnitude (not direction) under this transformation. The magnitude by which this eigenvector is scaled is called the \textbf{eigenvalue}, denoted $\lambda$.

The relationship between a matrix $A$, its eigenvalues $\lambda$, and eigenvectors $\underline{x}$ is given by the equation:

$$A \underline{x} = \lambda \underline{x}$$

This is known as the \textbf{definition of eigenvalues and eigenvectors}.

\section{Eigenvalue Equation}

To find the eigenvalues $\lambda$ of a matrix $A$, we solve the equation:
$$|A - \lambda I| = 0$$

\section{Eigenvector Equation}

To find the eigenvectors $\underline{x}$ corresponding to a specific eigenvalue $\lambda$, we solve the equation:
$$(A - \lambda I) \underline{x} = \underline{0}$$

\section{Derivation of Eigenvalue and Eigenvector Equations}

To find the eigenvector equation, we can rearrange the definition of eigenvalues and eigenvectors. 

$$
\begin{aligned}
A \underline{x} &= \lambda \underline{x} \\
\iff A \underline{x} &= \lambda I \underline{x} \\
\iff A \underline{x} - \lambda \underline{x} &= \underline{0} \\
\iff (A - \lambda I) \underline{x} &= \underline{0} \\
\end{aligned}
$$

To find the eigenvalue equation, note that eigenvectors are non-zero vectors $\underline{x} \neq \underline{0}$. Therefore, the equation $(A - \lambda I) \underline{x} = \underline{0}$ must have non-trivial solutions. This occurs when the matrix $(A - \lambda I)$ is singular, when its determinant is zero:
$$|A - \lambda I| = 0$$

Therefore, we have derived both the eigenvalue and eigenvector equations from the definition of eigenvalues and eigenvectors.

\section{Problems}